# -*- coding: utf-8 -*-
"""Another copy of Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v783zjaWkLkbkRDZVj37NIKSGIV-Q5ed
"""

pip install astropy astroquery scipy pandas numpy

pip install lenscat

from lenscat import catalog
import pandas as pd

# Load lens catalog
df = catalog.to_pandas()

# Select strong lenses, e.g., graded as 'definite' or 'probable'
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list = list(zip(df_strong['RA'], df_strong['DEC']))

# Then feed `lens_list` into the batch script above

# Install required packages if not already
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Config --------------------------------------------------------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3
lens_batch_size = 50
padding = 2.0

# --- Fetch Lens Coordinates ---------------------------------------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list = list(zip(df_strong['RA'], df_strong['DEC']))
print(f"✅ Retrieved {len(lens_list)} strong lenses.")

# --- SIMBAD Setup --------------------------------------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# --- Query Function ------------------------------------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None: return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay); delay *= 2
    return 0

# --- Random Point Generator ---------------------------------------------
def generate_random_points(N, ra_bounds, dec_bounds, exclusion_coords):
    pts, attempts = [], 0
    while len(pts) < N and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        pt = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if pt.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(pt)
    if len(pts) < N:
        print(f"⚠ Only generated {len(pts)} random points after {attempts} attempts.")
    return pts

# --- Batch Analysis Function --------------------------------------------
def analyze_batch(list_coords, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords]*u.deg,
                           dec=[c[1] for c in list_coords]*u.deg)
    print(f"\n=== Batch {batch_num}: {len(list_coords)} lenses ===")

    # LENS counts
    lens_data = []
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1}", ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # RANDOM counts
    ra_vals, dec_vals = df_l['ra'], df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding

    rand_points = generate_random_points(len(list_coords),
                                         (ra_min, ra_max), (dec_min, dec_max),
                                         lens_coords)
    rand_data = []
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # STATS
    print("📊 Stats (Lens vs Random):")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]; R = df_r[f"random_count_{r}"]
        print(f"\nRadius {r}′ - MeanLens: {L.mean():.1f}, MeanRand: {R.mean():.1f}")
        print(f"Zeros: Lens { (L==0).sum() }, Rand { (R==0).sum() }")
        ks, p = ks_2samp(L, R); pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"KS p={p:.3f}, MinPoisson p={pois_p:.2e}")
    return df_l, df_r

# --- Run in Batches ------------------------------------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

for idx, batch in enumerate(chunk(lens_list, lens_batch_size), start=1):
    analyze_batch(batch, idx)

# --- Install required packages if needed:
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Configurable Parameters ----------------------------------------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3
lens_batch_size = 50
padding = 2.0

# --- Fetch Real Lens Coordinates -----------------------------------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list_200 = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"\n✅ Retrieved {len(lens_list_200)} strong lenses for analysis.")

# --- SIMBAD Setup --------------------------------------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# --- SIMBAD Query Function -----------------------------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None: return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay); delay *= 2
    return 0

# --- Generate Random Points ---------------------------------------------
def generate_random_points(N, ra_bounds, dec_bounds, exclusion_coords):
    pts, attempts = [], 0
    while len(pts) < N and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        pt = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if pt.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(pt)
    if len(pts) < N:
        print(f"⚠ Only generated {len(pts)} random points after {attempts} attempts.")
    return pts

# --- Analyze One Batch --------------------------------------------------
def analyze_batch(list_coords, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords]*u.deg,
                           dec=[c[1] for c in list_coords]*u.deg)
    print(f"\n=== Batch {batch_num}: {len(list_coords)} lenses ===")

    # LENS counts
    lens_data = []
    print("🔍 Querying SIMBAD around lenses...")
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1}", ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # RANDOM counts
    ra_vals, dec_vals = df_l['ra'], df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding

    print("🎯 Generating random points...")
    rand_points = generate_random_points(len(list_coords),
                                         (ra_min, ra_max), (dec_min, dec_max),
                                         lens_coords)

    rand_data = []
    print("🔍 Querying SIMBAD around randoms...")
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # STATS
    print("📊 Stats (Lens vs Random):")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]; R = df_r[f"random_count_{r}"]
        print(f"\nRadius {r}′ - MeanLens: {L.mean():.1f}, MeanRand: {R.mean():.1f}")
        print(f"Zeros: Lens { (L==0).sum() }, Rand { (R==0).sum() }")
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"KS p={p:.3f}, MinPoisson p={pois_p:.2e}")

    return df_l, df_r

# --- Chunking Utility --------------------------------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

# --- Run All Batches ---------------------------------------------------
for idx, batch in enumerate(chunk(lens_list_200, lens_batch_size), start=1):
    analyze_batch(batch, idx)



# --- Install required packages if needed:
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# ---------------- Configurable Parameters ----------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3            # Minimum distance between randoms and any lens
lens_batch_size = 50         # Process in batches
padding = 2.0                # Padding to bounding box for random region

# ---------------- Fetch Lens Coordinates -----------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list_200 = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"✅ Loaded {len(lens_list_200)} strong lenses from `lenscat`.")

# ---------------- SIMBAD Setup ---------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# ---------------- SIMBAD Query ---------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None:
                return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay)
            delay *= 2
    return 0

# ---------------- Generate Random Points ------------------
def generate_random_points(N, ra_bounds, dec_bounds, exclusion_coords):
    pts, attempts = [], 0
    while len(pts) < N and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        pt = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if pt.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(pt)
    if len(pts) < N:
        print(f"⚠️ Only generated {len(pts)} randoms after {attempts} attempts.")
    return pts

# ---------------- Batch Analyzer --------------------------
def analyze_batch(list_coords, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords]*u.deg,
                           dec=[c[1] for c in list_coords]*u.deg)
    print(f"\n=== Batch {batch_num} — {len(list_coords)} lenses ===")

    # --- Lens counts ---
    lens_data = []
    print("🔍 Querying SIMBAD near lenses...")
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1}", ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # --- Random region bounds ---
    ra_vals = df_l['ra']
    dec_vals = df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding

    # --- Random counts ---
    print("🎯 Generating random points...")
    rand_points = generate_random_points(len(list_coords), (ra_min, ra_max), (dec_min, dec_max), lens_coords)

    rand_data = []
    print("🔍 Querying SIMBAD near random points...")
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # --- Statistics ---
    print("📊 Lens vs Random stats:")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]
        R = df_r[f"random_count_{r}"]
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"\nRadius {r}′:")
        print(f"  🔹 Mean (Lens): {L.mean():.1f}, Mean (Random): {R.mean():.1f}")
        print(f"  🔹 Zeros — Lens: { (L==0).sum() }, Random: { (R==0).sum() }")
        print(f"  🔹 KS p={p:.3f}, Min Poisson p={pois_p:.2e}")
    return df_l, df_r

# ---------------- Chunk Utility ---------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

# ---------------- Execute Analysis -------------------------
for idx, batch in enumerate(chunk(lens_list_200, lens_batch_size), start=1):
    df_lens, df_rand = analyze_batch(batch, idx)
    # Optional: save per batch if needed
    # df_lens.to_csv(f"lens_batch_{idx}.csv", index=False)
    # df_rand.to_csv(f"random_batch_{idx}.csv", index=False)

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os


# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bullet_z = 0.296
z_tol = 0.05
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_related.csv'


# Conservative BH-related SIMBAD types
bh_types = [
   'AGN', 'QSO', 'BLLac', 'X', 'Rad', 'EmG', 'Seyfert', 'Sy1', 'Sy2',
   'LINER', 'BH?', 'BLAZAR'
]


# Clear cache to force fresh query
if os.path.exists(catalog_filename):
   os.remove(catalog_filename)
   print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")


bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)


custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype', 'rvz_redshift')  # Request object types and redshift


print(f"Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
if result is None:
   raise ValueError("SIMBAD query returned no results.")


print(f"Total SIMBAD objects returned: {len(result)}")
df = result.to_pandas()


# Convert redshift column to numeric, coercing errors to NaN
df['rvz_redshift'] = pd.to_numeric(df['rvz_redshift'], errors='coerce')


# Filter rows by BH types (case-insensitive exact match)
pattern = '|'.join(bh_types)
df_filtered = df[df['otype'].str.fullmatch(pattern, case=False, na=False)]


# Filter by redshift within tolerance
df_filtered = df_filtered[
   (df_filtered['rvz_redshift'] >= bullet_z - z_tol) &
   (df_filtered['rvz_redshift'] <= bullet_z + z_tol)
]


if df_filtered.empty:
   raise ValueError("No BH-related objects found within redshift window.")


coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
df_filtered.loc[:, 'ra'] = coords.ra.deg
df_filtered.loc[:, 'dec'] = coords.dec.deg


df_filtered[['main_id', 'ra', 'dec', 'otype', 'rvz_redshift']].to_csv(catalog_filename, index=False)
print(f"Saved {len(df_filtered)} BH-related sources to {catalog_filename}")


# Define bounding box around Bullet Cluster
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2


agn_subset = df_filtered[
   (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
   (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]


if agn_subset.empty:
   raise ValueError("No BH-related sources found within bounding box.")


agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")


ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)


cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)


# Count observed near cluster center
observed_counts = {}
for radius in radii_arcmin:
   sep = cluster_center.separation(agn_coords)
   count = np.sum(sep < radius * u.arcmin)
   observed_counts[radius] = count


# Count near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
   rand_ra = np.random.uniform(ra_min, ra_max)
   rand_dec = np.random.uniform(dec_min, dec_max)
   rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)


   for radius in radii_arcmin:
       sep = rand_point.separation(agn_coords)
       count = np.sum(sep < radius * u.arcmin)
       random_counts[radius].append(count)


print("\n=== BH-related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
   obs = observed_counts[radius]
   rand_list = np.array(random_counts[radius])
   mean_rand = rand_list.mean()
   p_poisson = poisson.sf(obs - 1, mean_rand)
   p_ks = ks_2samp([obs], rand_list).pvalue
   print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

# --- Install required packages if needed:
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# ---------------- Configurable Parameters ----------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3            # Minimum distance between randoms and any lens
lens_batch_size = 50         # Process in batches
padding = 2.0                # Padding to bounding box for random region

# ---------------- Fetch Lens Coordinates -----------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list_200 = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"✅ Loaded {len(lens_list_200)} strong lenses from `lenscat`.")

# ---------------- SIMBAD Setup ---------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# ---------------- SIMBAD Query ---------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None:
                return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay)
            delay *= 2
    return 0

# ---------------- Generate Random Points ------------------
def generate_random_points(N, ra_bounds, dec_bounds, exclusion_coords):
    pts, attempts = [], 0
    while len(pts) < N and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        pt = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if pt.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(pt)
    if len(pts) < N:
        print(f"⚠️ Only generated {len(pts)} randoms after {attempts} attempts.")
    return pts

# ---------------- Batch Analyzer --------------------------
def analyze_batch(list_coords, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords]*u.deg,
                           dec=[c[1] for c in list_coords]*u.deg)
    print(f"\n=== Batch {batch_num} — {len(list_coords)} lenses ===")

    # --- Lens counts ---
    lens_data = []
    print("🔍 Querying SIMBAD near lenses...")
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1}", ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # --- Random region bounds ---
    ra_vals = df_l['ra']
    dec_vals = df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding

    # --- Random counts ---
    print("🎯 Generating random points...")
    rand_points = generate_random_points(len(list_coords), (ra_min, ra_max), (dec_min, dec_max), lens_coords)

    rand_data = []
    print("🔍 Querying SIMBAD near random points...")
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # --- Statistics ---
    print("📊 Lens vs Random stats:")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]
        R = df_r[f"random_count_{r}"]
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"\nRadius {r}′:")
        print(f"  🔹 Mean (Lens): {L.mean():.1f}, Mean (Random): {R.mean():.1f}")
        print(f"  🔹 Zeros — Lens: { (L==0).sum() }, Random: { (R==0).sum() }")
        print(f"  🔹 KS p={p:.3f}, Min Poisson p={pois_p:.2e}")
    return df_l, df_r

# ---------------- Chunk Utility ---------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

# ---------------- Execute Analysis -------------------------
for idx, batch in enumerate(chunk(lens_list_200, lens_batch_size), start=1):
    df_lens, df_rand = analyze_batch(batch, idx)
    # Optional: save per batch if needed
    # df_lens.to_csv(f"lens_batch_{idx}.csv", index=False)
    # df_rand.to_csv(f"random_batch_{idx}.csv", index=False)

# --- Install these first if needed:
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Config ----------------------------------------------------------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3
large_query_radius_deg = 1.0
lens_batch_size = 50

# --- Load lenses from lenscat ---------------------------------------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"✅ Loaded {len(lens_list)} confident/probable lenses.")

# --- Convert to SkyCoord --------------------------------------------------
lens_coords_all = SkyCoord(
    ra=[x[0] for x in lens_list]*u.deg,
    dec=[x[1] for x in lens_list]*u.deg
)

# --- Setup SIMBAD ---------------------------------------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

def query_simbad_large_radius(coord, radius_deg):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_deg * u.deg)
            if result is None:
                return pd.DataFrame()
            return result.to_pandas()
        except (ConnectionError, TimeoutError, Exception):
            time.sleep(delay)
            delay *= 2
    return pd.DataFrame()

def count_objects_in_radii(coord_center, coords_all, radii_arcmin):
    if coords_all.empty:
        return [0]*len(radii_arcmin)
    sky_coords = SkyCoord(coords_all['ra'], coords_all['dec'], unit=(u.deg, u.deg))
    separations = coord_center.separation(sky_coords).arcminute
    return [np.sum(separations <= r) for r in radii_arcmin]

def generate_random_points(n_points, ra_bounds, dec_bounds, exclusion_coords, min_sep_deg, max_attempts=30000):
    random_points = []
    attempts = 0
    while len(random_points) < n_points and attempts < max_attempts:
        attempts += 1
        ra_rand = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec_rand = np.degrees(np.arcsin(sin_dec))
        candidate = SkyCoord(ra=ra_rand*u.deg, dec=dec_rand*u.deg)
        if candidate.separation(exclusion_coords).deg.min() >= min_sep_deg:
            random_points.append(candidate)
        if attempts % 1000 == 0:
            print(f"Attempt {attempts}: {len(random_points)} random points generated")
    if len(random_points) < n_points:
        print(f"⚠️ Only generated {len(random_points)} random points after {attempts} attempts.")
    return random_points

def analyze_batch(lens_coords, batch_number=1):
    print(f"\n=== Batch {batch_number} with {len(lens_coords)} lenses ===")

    # --- Query SIMBAD around lenses --------------------------------------
    lens_results = []
    print("🔍 Querying SIMBAD for lenses...")
    for i, coord in enumerate(lens_coords):
        df_full = query_simbad_large_radius(coord, large_query_radius_deg)
        if df_full.empty:
            counts = [0]*len(radii_arcmin)
        else:
            mask = df_full['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)
            df_filtered = df_full[mask]
            counts = count_objects_in_radii(coord, df_filtered, radii_arcmin)
        lens_results.append({
            'lens': f"Lens_{(batch_number-1)*lens_batch_size + i + 1}",
            'ra': coord.ra.deg,
            'dec': coord.dec.deg,
            **{f'count_{r}arcmin': counts[j] for j, r in enumerate(radii_arcmin)}
        })
        print(f"Lens_{i+1} counts: {counts}")
        time.sleep(0.5)

    df_lens = pd.DataFrame(lens_results)

    # --- Random Point Generation -----------------------------------------
    ra_vals = [c.ra.deg for c in lens_coords]
    dec_vals = [c.dec.deg for c in lens_coords]
    ra_bounds = (min(ra_vals) - min_sep_deg*2, max(ra_vals) + min_sep_deg*2)
    dec_bounds = (min(dec_vals) - min_sep_deg*2, max(dec_vals) + min_sep_deg*2)

    print("🎯 Generating random points...")
    random_points = generate_random_points(
        len(lens_coords),
        ra_bounds,
        dec_bounds,
        exclusion_coords=lens_coords_all,
        min_sep_deg=min_sep_deg
    )

    # --- Query SIMBAD for random points ----------------------------------
    random_results = []
    print("🔍 Querying SIMBAD for random points...")
    for i, coord in enumerate(random_points):
        df_full = query_simbad_large_radius(coord, large_query_radius_deg)
        if df_full.empty:
            counts = [0]*len(radii_arcmin)
        else:
            mask = df_full['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)
            df_filtered = df_full[mask]
            counts = count_objects_in_radii(coord, df_filtered, radii_arcmin)
        random_results.append({
            'ra': coord.ra.deg,
            'dec': coord.dec.deg,
            **{f'random_count_{r}arcmin': counts[j] for j, r in enumerate(radii_arcmin)}
        })
        print(f"Random_{i+1} counts: {counts}")
        time.sleep(0.5)

    df_rand = pd.DataFrame(random_results)

    # --- Stats -----------------------------------------------------------
    print("\n📊 Lens vs Random stats:")
    for r in radii_arcmin:
        L = df_lens[f'count_{r}arcmin']
        R = df_rand[f'random_count_{r}arcmin']
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"Radius {r}′:")
        print(f"  🔹 Mean Lens = {L.mean():.1f}, Mean Random = {R.mean():.1f}")
        print(f"  🔹 Zeros — Lens: {(L==0).sum()}, Random: {(R==0).sum()}")
        print(f"  🔹 KS p = {p:.3f}, Poisson min p = {pois_p:.2e}")

    return df_lens, df_rand

def chunk_list(lst, size):
    for i in range(0, len(lst), size):
        yield lst[i:i+size]

# --- Run all batches ------------------------------------------------------
for batch_num, batch_coords in enumerate(chunk_list(lens_coords_all, lens_batch_size), start=1):
    df_lens_batch, df_rand_batch = analyze_batch(batch_coords, batch_num)
    # Optional: save results, append to global lists, etc.

!pip install lenscat

# --- Save and show raw counts ---
    df_l.index = [f"Lens_{i+1}" for i in range(len(df_l))]
    df_r.index = [f"Random_{i+1}" for i in range(len(df_r))]

    print("\n📋 Raw lens counts:")
    print(df_l[[f"count_{r}" for r in radii_arcmin]])

    print("\n📋 Raw random counts:")
    print(df_r[[f"random_count_{r}" for r in radii_arcmin]])

    # Save for further analysis
    df_l.to_csv(f"lens_batch_{batch_num}.csv", index=False)
    df_r.to_csv(f"random_batch_{batch_num}.csv", index=False)

    return df_l, df_r

# --- Save and show raw counts ---
    df_l.index = [f"Lens_{i+1}" for i in range(len(df_l))]
    df_r.index = [f"Random_{i+1}" for i in range(len(df_r))]

    print("\n📋 Raw lens counts:")
    print(df_l[['lens', f'count_{radii_arcmin[0]}', f'count_{radii_arcmin[1]}', f'count_{radii_arcmin[2]}']])

    print("\n📋 Raw random counts:")
    print(df_r[[f'ra', f'dec', f'random_count_{radii_arcmin[0]}', f'random_count_{radii_arcmin[1]}', f'random_count_{radii_arcmin[2]}']])

    # Save for further inspection
    df_l.to_csv(f"lens_batch_{batch_num}.csv", index=False)
    df_r.to_csv(f"random_batch_{batch_num}.csv", index=False)

    return df_l, df_r

# --- Print raw lens counts ---
df_l.index = [f"Lens_{i+1}" for i in range(len(df_l))]
print("\n📋 Raw lens counts:")
print(df_l[['lens', f'count_{radii_arcmin[0]}', f'count_{radii_arcmin[1]}', f'count_{radii_arcmin[2]}']])

# ✅ Print raw SIMBAD counts from latest lens query
print("\n📋 Raw SIMBAD counts for lenses:")
print(df_lens[['lens'] + [f'count_{r}' for r in radii_arcmin]])

# --- Install required packages if needed:
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Configurable Parameters ----------------------------------------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3
lens_batch_size = 50
padding = 2.0

# --- Fetch Real Lens Coordinates -----------------------------------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list_200 = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"\n✅ Retrieved {len(lens_list_200)} strong lenses for analysis.")

# --- SIMBAD Setup --------------------------------------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# --- SIMBAD Query Function -----------------------------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None: return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay); delay *= 2
    return 0

# --- Generate Random Points ---------------------------------------------
def generate_random_points(N, ra_bounds, dec_bounds, exclusion_coords):
    pts, attempts = [], 0
    while len(pts) < N and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        pt = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if pt.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(pt)
    if len(pts) < N:
        print(f"⚠ Only generated {len(pts)} random points after {attempts} attempts.")
    return pts

# --- Analyze One Batch --------------------------------------------------
def analyze_batch(list_coords, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords]*u.deg,
                           dec=[c[1] for c in list_coords]*u.deg)
    print(f"\n=== Batch {batch_num}: {len(list_coords)} lenses ===")

    # LENS counts
    lens_data = []
    print("🔍 Querying SIMBAD around lenses...")
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1}", ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # RANDOM counts
    ra_vals, dec_vals = df_l['ra'], df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding

    print("🎯 Generating random points...")
    rand_points = generate_random_points(len(list_coords),
                                         (ra_min, ra_max), (dec_min, dec_max),
                                         lens_coords)

    rand_data = []
    print("🔍 Querying SIMBAD around randoms...")
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # STATS
    print("📊 Stats (Lens vs Random):")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]; R = df_r[f"random_count_{r}"]
        print(f"\nRadius {r}′ - MeanLens: {L.mean():.1f}, MeanRand: {R.mean():.1f}")
        print(f"Zeros: Lens { (L==0).sum() }, Rand { (R==0).sum() }")
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"KS p={p:.3f}, MinPoisson p={pois_p:.2e}")

    return df_l, df_r

# --- Chunking Utility --------------------------------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

# --- Run All Batches ---------------------------------------------------
for idx, batch in enumerate(chunk(lens_list_200, lens_batch_size), start=1):
    analyze_batch(batch, idx)

# --- Install required packages if needed:
# pip install lenscat astropy astroquery scipy pandas numpy

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Configurable Parameters ----------------------------------------------
radii_arcmin = [10, 15, 20]     # Updated radii
min_sep_deg = 0.3               # Minimum separation (deg) between random points and ANY lens
lens_batch_size = 50
padding = 2.0                   # Padding for random point generation box

# --- Fetch Real Lens Coordinates -----------------------------------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list_200 = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"\n✅ Retrieved {len(lens_list_200)} strong lenses for analysis.")

# --- SIMBAD Setup --------------------------------------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# --- SIMBAD Query Function -----------------------------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None:
                return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay)
            delay *= 2
    return 0

# --- Generate Random Points ---------------------------------------------
def generate_random_points(N, ra_bounds, dec_bounds, exclusion_coords):
    pts = []
    attempts = 0
    while len(pts) < N and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        pt = SkyCoord(ra=ra * u.deg, dec=dec * u.deg)
        if pt.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(pt)
    if len(pts) < N:
        print(f"⚠️ Only generated {len(pts)} random points after {attempts} attempts.")
    return pts

# --- Analyze One Batch --------------------------------------------------
def analyze_batch(list_coords, batch_num, all_lens_coords):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords] * u.deg,
                           dec=[c[1] for c in list_coords] * u.deg)
    print(f"\n=== Batch {batch_num}: {len(list_coords)} lenses ===")

    # --- Lens counts ---
    lens_data = []
    print("🔍 Querying SIMBAD around lenses...")
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i + 1 + (batch_num-1)*lens_batch_size}",
                              ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # --- Random region bounds ---
    ra_vals = df_l['ra']
    dec_vals = df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding

    # --- Random counts ---
    print("🎯 Generating random points...")
    rand_points = generate_random_points(len(list_coords), (ra_min, ra_max), (dec_min, dec_max), all_lens_coords)

    rand_data = []
    print("🔍 Querying SIMBAD around random points...")
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # --- Statistics ---
    print("📊 Lens vs Random stats:")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]
        R = df_r[f"random_count_{r}"]
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"\nRadius {r}′:")
        print(f"  🔹 Mean (Lens): {L.mean():.1f}, Mean (Random): {R.mean():.1f}")
        print(f"  🔹 Zeros — Lens: {(L == 0).sum()}, Random: {(R == 0).sum()}")
        print(f"  🔹 KS p={p:.3f}, Min Poisson p={pois_p:.2e}")

    return df_l, df_r

# --- Chunk Utility ------------------------------------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i + size]

# --- Prepare all lenses coords once for exclusion in random generation ---
all_lens_coords = SkyCoord(ra=[c[0] for c in lens_list_200] * u.deg,
                           dec=[c[1] for c in lens_list_200] * u.deg)

# --- Run All Batches ---------------------------------------------------
for idx, batch in enumerate(chunk(lens_list_200, lens_batch_size), start=1):
    analyze_batch(batch, idx, all_lens_coords)

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson

# Config
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3            # Minimum separation for random points from any lens
large_query_radius_deg = 1.0 # Large radius to query SIMBAD once per lens/random
lens_batch_size = 50

# Example lens list (replace with your real list)
lens_list = [
    (148.808454, 1.944930),
    (149.325213, 1.949342),
    (149.770970, 2.478957),
    (149.200682, 2.024675),
    # ... your 200 lenses here ...
]

# Setup SIMBAD
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

def query_simbad_large_radius(coord, radius_deg):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_deg * u.deg)
            if result is None:
                return pd.DataFrame()
            return result.to_pandas()
        except (ConnectionError, TimeoutError, Exception):
            time.sleep(delay)
            delay *= 2
    return pd.DataFrame()

def count_objects_in_radii(coord_center, coords_all, radii_arcmin):
    if coords_all.empty:
        return [0]*len(radii_arcmin)
    sky_coords = SkyCoord(coords_all['ra'], coords_all['dec'], unit=(u.deg, u.deg))
    separations = coord_center.separation(sky_coords).arcminute
    return [np.sum(separations <= r) for r in radii_arcmin]

def generate_random_points(n_points, ra_bounds, dec_bounds, exclusion_coords, min_sep_deg, max_attempts=30000):
    random_points = []
    attempts = 0
    while len(random_points) < n_points and attempts < max_attempts:
        attempts += 1
        ra_rand = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec_rand = np.degrees(np.arcsin(sin_dec))
        candidate = SkyCoord(ra=ra_rand*u.deg, dec=dec_rand*u.deg)
        if candidate.separation(exclusion_coords).deg.min() >= min_sep_deg:
            random_points.append(candidate)
        if attempts % 1000 == 0:
            print(f"Attempt {attempts}: {len(random_points)} random points generated")
    if len(random_points) < n_points:
        print(f"⚠️ Only generated {len(random_points)} random points after {attempts} attempts.")
    return random_points

def analyze_batch(lens_coords, batch_number=1):
    print(f"\n=== Batch {batch_number} with {len(lens_coords)} lenses ===")

    # Query lenses with large radius and count inside smaller radii
    lens_results = []
    print("🔍 Querying SIMBAD for lenses...")
    for i, coord in enumerate(lens_coords):
        df_full = query_simbad_large_radius(coord, large_query_radius_deg)
        if df_full.empty:
            counts = [0]*len(radii_arcmin)
        else:
            mask = df_full['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)
            df_filtered = df_full[mask]
            counts = count_objects_in_radii(coord, df_filtered, radii_arcmin)
        lens_results.append({
            'lens': f"Lens_{(batch_number-1)*lens_batch_size + i + 1}",
            'ra': coord.ra.deg,
            'dec': coord.dec.deg,
            **{f'count_{r}arcmin': counts[j] for j, r in enumerate(radii_arcmin)}
        })
        print(f"Lens_{i+1} counts: {counts}")
        time.sleep(0.5)  # Respect SIMBAD limits

    df_lens = pd.DataFrame(lens_results)

    # Generate random points avoiding lenses by min_sep_deg
    ra_vals = [c.ra.deg for c in lens_coords]
    dec_vals = [c.dec.deg for c in lens_coords]
    ra_bounds = (min(ra_vals) - min_sep_deg*2, max(ra_vals) + min_sep_deg*2)
    dec_bounds = (min(dec_vals) - min_sep_deg*2, max(dec_vals) + min_sep_deg*2)
    print("🎯 Generating random points...")
    random_points = generate_random_points(len(lens_coords), ra_bounds, dec_bounds, lens_coords, min_sep_deg)

    # Query SIMBAD for random points
    random_results = []
    print("🔍 Querying SIMBAD for random points...")
    for i, coord in enumerate(random_points):
        df_full = query_simbad_large_radius(coord, large_query_radius_deg)
        if df_full.empty:
            counts = [0]*len(radii_arcmin)
        else:
            mask = df_full['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)
            df_filtered = df_full[mask]
            counts = count_objects_in_radii(coord, df_filtered, radii_arcmin)
        random_results.append({
            'ra': coord.ra.deg,
            'dec': coord.dec.deg,
            **{f'random_count_{r}arcmin': counts[j] for j, r in enumerate(radii_arcmin)}
        })
        print(f"Random_{i+1} counts: {counts}")
        time.sleep(0.5)

    df_rand = pd.DataFrame(random_results)

    # Stats
    print("\n📊 Lens vs Random stats:")
    for r in radii_arcmin:
        L = df_lens[f'count_{r}arcmin']
        R = df_rand[f'random_count_{r}arcmin']
        ks, p = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"Radius {r}′:")
        print(f"  Mean Lens = {L.mean():.1f}, Mean Random = {R.mean():.1f}")
        print(f"  Zeros Lens = {(L==0).sum()}, Random = {(R==0).sum()}")
        print(f"  KS p-value = {p:.3f}, Poisson min p = {pois_p:.2e}")

    return df_lens, df_rand

def chunk_list(lst, size):
    for i in range(0, len(lst), size):
        yield lst[i:i+size]

# Convert lens list to SkyCoord list
lens_coords_all = SkyCoord(ra=[x[0] for x in lens_list]*u.deg,
                           dec=[x[1] for x in lens_list]*u.deg)

# Run batches
for batch_num, batch_coords in enumerate(chunk_list(lens_coords_all, lens_batch_size), start=1):
    df_lens_batch, df_rand_batch = analyze_batch(batch_coords, batch_num)
    # Optional: save or accumulate results

from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError

# Custom SIMBAD setup
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120  # Increase timeout if SIMBAD is slow

# Reset fields to default and then add specific fields
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')  # Object type (e.g., AGN, QSO)

!pip install astroquery

from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Parameters ----------------------------------------------------------
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.15              # Minimum separation from any known lens
lens_batch_size = 50
padding = 2.0                   # Bounding box padding for random region

# --- Load Known Lenses --------------------------------------------------
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
all_lens_coords = SkyCoord(ra=df_strong['RA'].values * u.deg,
                           dec=df_strong['DEC'].values * u.deg)
lens_list_200 = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"✅ Loaded {len(lens_list_200)} strong lenses.")

# --- SIMBAD Setup -------------------------------------------------------
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# --- Query SIMBAD Counts ------------------------------------------------
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None:
                return 0
            df = result.to_pandas()
            return df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay)
            delay *= 2
    return 0

# --- Generate Clean Random Points ---------------------------------------
def generate_random_points(n, ra_bounds, dec_bounds, exclusion_coords, min_sep_deg=0.15, max_attempts=50000):
    pts, attempts = [], 0
    while len(pts) < n and attempts < max_attempts:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        candidate = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if candidate.separation(exclusion_coords).deg.min() >= min_sep_deg:
            pts.append(candidate)
        if attempts % 1000 == 0:
            print(f"  Attempt {attempts} — Randoms found: {len(pts)}")
    if len(pts) < n:
        print(f"⚠ Only generated {len(pts)} random points after {attempts} attempts.")
    return pts

# --- Analyze One Batch --------------------------------------------------
def analyze_batch(list_coords, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in list_coords]*u.deg,
                           dec=[c[1] for c in list_coords]*u.deg)
    print(f"\n=== Batch {batch_num} — {len(list_coords)} lenses ===")

    # LENS counts
    lens_data = []
    print("🔍 Querying SIMBAD around lenses...")
    for i, c in enumerate(lens_coords):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1+(batch_num-1)*lens_batch_size}",
                              ra=c.ra.deg, dec=c.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_l = pd.DataFrame(lens_data)

    # RANDOMS
    ra_vals, dec_vals = df_l['ra'], df_l['dec']
    ra_min, ra_max = ra_vals.min() - padding, ra_vals.max() + padding
    dec_min, dec_max = dec_vals.min() - padding, dec_vals.max() + padding
    print("🎯 Generating clean random points (no overlap with ANY lens)...")
    rand_points = generate_random_points(len(list_coords),
                                         (ra_min, ra_max), (dec_min, dec_max),
                                         exclusion_coords=all_lens_coords,
                                         min_sep_deg=min_sep_deg)

    rand_data = []
    print("🔍 Querying SIMBAD around randoms...")
    for i, c in enumerate(rand_points):
        counts = [query_simbad_count(c, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=c.ra.deg, dec=c.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_r = pd.DataFrame(rand_data)

    # STATS
    print("📊 Lens vs Random stats:")
    for r in radii_arcmin:
        L = df_l[f"count_{r}"]
        R = df_r[f"random_count_{r}"]
        ks, p = ks_2samp(L, R)
        pois_p = min([poisson.sf(x - 1, R.mean()) for x in L])
        print(f"\nRadius {r} arcmin:")
        print(f"  🔹 Lens mean: {L.mean():.2f} | Random mean: {R.mean():.2f}")
        print(f"  🔹 Zeros — Lens: {(L==0).sum()}, Random: {(R==0).sum()}")
        print(f"  🔹 KS p={p:.3f}, Min Poisson p={pois_p:.2e}")
    return df_l, df_r

# --- Chunking Utility ---------------------------------------------------
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

# --- Execute All Batches ------------------------------------------------
for idx, batch in enumerate(chunk(lens_list_200, lens_batch_size), start=1):
    df_l, df_r = analyze_batch(batch, idx)
    # Optional: Save intermediate results
    # df_l.to_csv(f"lens_batch_{idx}.csv", index=False)
    # df_r.to_csv(f"random_batch_{idx}.csv", index=False)

from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad

coord = SkyCoord(ra=148.808454*u.deg, dec=1.944930*u.deg)  # example
custom_simbad = Simbad()
custom_simbad.add_votable_fields('otype')

for radius in [10, 15, 20]:
    result = custom_simbad.query_region(coord, radius=radius * u.arcmin)
    if result:
        df = result.to_pandas()
        count = df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False).sum()
        print(f"{radius}′ → {count} AGNs")
    else:
        print(f"{radius}′ → No results")

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Parameters ---
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3
lens_batch_size = 50
padding = 2.0

# --- SIMBAD Setup ---
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

# --- Query SIMBAD for BHs ---
def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for attempt in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None:
                return 0
            df = result.to_pandas()
            return df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False).sum()
        except (ConnectionError, TimeoutError, Exception):
            time.sleep(delay)
            delay *= 2
    return 0

# --- Generate Clean Randoms ---
def generate_random_points(n_points, ra_bounds, dec_bounds, exclusion_coords):
    points, attempts = [], 0
    while len(points) < n_points and attempts < 30000:
        attempts += 1
        ra = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec = np.degrees(np.arcsin(sin_dec))
        candidate = SkyCoord(ra=ra*u.deg, dec=dec*u.deg)
        if candidate.separation(exclusion_coords).deg.min() >= min_sep_deg:
            points.append(candidate)
    return points

# --- Analyze One Batch ---
def analyze_batch(lens_list, batch_number=1):
    lens_coords = SkyCoord(ra=[x[0] for x in lens_list]*u.deg, dec=[x[1] for x in lens_list]*u.deg)
    print(f"\n=== Batch {batch_number} ===")

    lens_results = []
    for i, coord in enumerate(lens_coords):
        counts = [query_simbad_count(coord, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_results.append({
            'lens': f'Lens_{i+1+(batch_number-1)*lens_batch_size}',
            'ra': coord.ra.deg,
            'dec': coord.dec.deg,
            **{f'count_{r}arcmin': counts[j] for j, r in enumerate(radii_arcmin)}
        })
    df_lens = pd.DataFrame(lens_results)

    ra_vals = df_lens['ra']
    dec_vals = df_lens['dec']
    ra_bounds = (ra_vals.min() - padding, ra_vals.max() + padding)
    dec_bounds = (dec_vals.min() - padding, dec_vals.max() + padding)

    rand_coords = generate_random_points(len(lens_list), ra_bounds, dec_bounds, lens_coords)

    rand_results = []
    for i, coord in enumerate(rand_coords):
        counts = [query_simbad_count(coord, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_results.append({
            'ra': coord.ra.deg,
            'dec': coord.dec.deg,
            **{f'random_count_{r}arcmin': counts[j] for j, r in enumerate(radii_arcmin)}
        })
    df_rand = pd.DataFrame(rand_results)

    print("\n📊 Stats:")
    for r in radii_arcmin:
        L = df_lens[f'count_{r}arcmin']
        R = df_rand[f'random_count_{r}arcmin']
        ks, p = ks_2samp(L, R)
        pois_p = min([poisson.sf(x-1, R.mean()) for x in L])
        print(f"Radius {r}′: Lens μ={L.mean():.1f}, Rand μ={R.mean():.1f}, Zeros: L={sum(L==0)}, R={sum(R==0)}, KS p={p:.3f}, Poisson p={pois_p:.2e}")

    return df_lens, df_rand

# --- Load 100 Strong Lenses ---
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])]
lens_list = list(zip(df_strong['RA'], df_strong['DEC']))[:100]

# --- Run in Batches ---
def chunk(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i + size]

for idx, batch in enumerate(chunk(lens_list, lens_batch_size), start=1):
    df_lens, df_rand = analyze_batch(batch, idx)

import time
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.exceptions import TimeoutError
from requests.exceptions import ConnectionError
from scipy.stats import ks_2samp, poisson
from lenscat import catalog

# --- Parameters ---
radii_arcmin = [10, 15, 20]
min_sep_deg = 0.3        # Minimum separation of randoms from *any* lens
lens_batch_size = 50
padding = 2.0            # Padding to bounding box for random region

# --- Load unique strong lenses ---
df = catalog.to_pandas()
df_strong = df[df['grading'].isin(['confident', 'probable'])].drop_duplicates(subset=['RA', 'DEC'])
lens_list = list(zip(df_strong['RA'], df_strong['DEC']))[:200]
print(f"✅ Loaded {len(lens_list)} unique strong lenses")

# --- Setup SIMBAD ---
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.reset_votable_fields()
custom_simbad.add_votable_fields('otype')

def query_simbad_count(coord, radius_arcmin):
    retries, delay = 5, 3
    for _ in range(retries):
        try:
            result = custom_simbad.query_region(coord, radius=radius_arcmin * u.arcmin)
            if result is None:
                return 0
            dfq = result.to_pandas()
            return dfq['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False).sum()
        except (ConnectionError, TimeoutError):
            time.sleep(delay)
            delay *= 2
    return 0

def generate_random_points(n_points, ra_bounds, dec_bounds, exclusion_coords):
    random_points = []
    attempts = 0
    while len(random_points) < n_points and attempts < 30000:
        attempts += 1
        ra_rand = np.random.uniform(*ra_bounds)
        sin_dec = np.random.uniform(np.sin(np.radians(dec_bounds[0])), np.sin(np.radians(dec_bounds[1])))
        dec_rand = np.degrees(np.arcsin(sin_dec))
        candidate = SkyCoord(ra=ra_rand*u.deg, dec=dec_rand*u.deg)
        # Reject if too close to any lens
        if candidate.separation(exclusion_coords).deg.min() >= min_sep_deg:
            random_points.append(candidate)
        if attempts % 1000 == 0:
            print(f"Attempt {attempts}: Generated {len(random_points)} random points")
    if len(random_points) < n_points:
        print(f"⚠️ Only generated {len(random_points)} random points after {attempts} attempts.")
    return random_points

def analyze_batch(lens_coords_batch, batch_num):
    lens_coords = SkyCoord(ra=[c[0] for c in lens_coords_batch]*u.deg,
                           dec=[c[1] for c in lens_coords_batch]*u.deg)
    print(f"\n=== Batch {batch_num}: {len(lens_coords)} lenses ===")

    # Query lenses
    lens_data = []
    print("🔍 Querying SIMBAD near lenses...")
    for i, coord in enumerate(lens_coords):
        counts = [query_simbad_count(coord, r) for r in radii_arcmin]
        time.sleep(0.3)
        lens_data.append(dict(lens=f"Lens_{i+1+(batch_num-1)*lens_batch_size}", ra=coord.ra.deg, dec=coord.dec.deg,
                              **{f"count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_lens = pd.DataFrame(lens_data)

    # Bounding box for random points (with padding)
    ra_min, ra_max = df_lens['ra'].min() - padding, df_lens['ra'].max() + padding
    dec_min, dec_max = df_lens['dec'].min() - padding, df_lens['dec'].max() + padding

    # Generate random points avoiding all lenses
    print("🎯 Generating random points...")
    rand_points = generate_random_points(len(lens_coords), (ra_min, ra_max), (dec_min, dec_max), lens_coords)

    # Query randoms
    rand_data = []
    print("🔍 Querying SIMBAD near random points...")
    for i, coord in enumerate(rand_points):
        counts = [query_simbad_count(coord, r) for r in radii_arcmin]
        time.sleep(0.3)
        rand_data.append(dict(ra=coord.ra.deg, dec=coord.dec.deg,
                              **{f"random_count_{r}": counts[j] for j, r in enumerate(radii_arcmin)}))
    df_rand = pd.DataFrame(rand_data)

    # Stats
    print("📊 Lens vs Random statistics:")
    for r in radii_arcmin:
        L = df_lens[f"count_{r}"]
        R = df_rand[f"random_count_{r}"]
        ks, p_ks = ks_2samp(L, R)
        pois_p = min(poisson.sf(L - 1, R.mean()))
        print(f"\nRadius {r}′:")
        print(f"  Lens mean = {L.mean():.1f}, Random mean = {R.mean():.1f}")
        print(f"  Lens zeros = {(L==0).sum()}, Random zeros = {(R==0).sum()}")
        print(f"  KS p-value = {p_ks:.3f}, Min Poisson p-value = {pois_p:.2e}")

    return df_lens, df_rand

def chunk_list(lst, size):
    for i in range(0, len(lst), size):
        yield lst[i:i + size]

# --- Run all batches ---
for batch_num, batch_lens in enumerate(chunk_list(lens_list, lens_batch_size), start=1):
    df_lens, df_rand = analyze_batch(batch_lens, batch_num)

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all objects near Bullet Cluster...")
    result = custom_simbad.query_region(bullet_coord, radius=0.5 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print("SIMBAD query columns:", result.colnames)
    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter AGN/QSO within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

# Copy to avoid SettingWithCopyWarning and convert to floats
agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

# DEBUG: check types and NaNs
print("RA dtype:", agn_subset['ra'].dtype)
print("DEC dtype:", agn_subset['dec'].dtype)
print("Any NaNs in RA?", agn_subset['ra'].isna().any())
print("Any NaNs in DEC?", agn_subset['dec'].isna().any())

# Drop rows with NaNs just in case
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

# Create SkyCoord with clean float arrays
ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_blackhole_related.csv'

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

# Extended filter including AGN, QSO, BLLac, and other BH-related types
bh_related_types = [
    'AGN', 'QSO', 'BLLac', 'XRB', 'BHXB', 'Sy1', 'Sy2', 'LINER', 'MicroQSO',
    'LMXB', 'HMXB', 'BLRG', 'ULX'
]
bh_filter_str = '|'.join(bh_related_types)

if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all black hole related objects near Bullet Cluster...")
    result = custom_simbad.query_region(bullet_coord, radius=0.5 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print("SIMBAD query columns:", result.colnames)
    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only black hole related types
    df_filtered = df[df['otype'].str.contains(bh_filter_str, case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No black hole related objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} black hole related sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter objects within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

bh_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if bh_subset.empty:
    raise ValueError("No black hole related objects found within bounding box. Check catalog or field depth.")

# Copy and convert types
bh_subset = bh_subset.copy()
bh_subset['ra'] = bh_subset['ra'].astype(float)
bh_subset['dec'] = bh_subset['dec'].astype(float)

# Drop NaNs
bh_subset = bh_subset.dropna(subset=['ra', 'dec'])

# Create SkyCoord
ra_vals = bh_subset['ra'].to_numpy(dtype=float)
dec_vals = bh_subset['dec'].to_numpy(dtype=float)
bh_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed black hole related objects near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(bh_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count near random points (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(bh_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print summary
print("\n=== Black Hole Related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3,5,10,15]   # <-- Updated radii here
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all objects near Bullet Cluster...")
    result = custom_simbad.query_region(bullet_coord, radius=0.5 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print("SIMBAD query columns:", result.colnames)
    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter AGN/QSO within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

# Copy to avoid SettingWithCopyWarning and convert to floats
agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

# DEBUG: check types and NaNs
print("RA dtype:", agn_subset['ra'].dtype)
print("DEC dtype:", agn_subset['dec'].dtype)
print("Any NaNs in RA?", agn_subset['ra'].isna().any())
print("Any NaNs in DEC?", agn_subset['dec'].isna().any())

# Drop rows with NaNs just in case
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

# Create SkyCoord with clean float arrays
ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3,5,10,15, 20, 25]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

# Query SIMBAD if no cache exists
if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all objects near Bullet Cluster...")
    result = custom_simbad.query_region(bullet_coord, radius=0.5 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print("SIMBAD query columns:", result.colnames)
    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter AGN/QSO within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

# Convert to float to avoid warnings
agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

# Drop NaNs just in case
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

# Create SkyCoord with clean floats
ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

Radius (arcmin)
Observed Count
Random Mean Count
Poisson p-value
KS test p-value
3
192
41.40
1.105 × 10⁻⁶⁴
8.392 × 10⁻²
5
536
112.87
2.839 × 10⁻¹⁸¹
1.179 × 10⁻¹
10
1803
408.34
< 1 × 10⁻³⁰⁰
7.592 × 10⁻²

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
query_radius_deg = 2.0  # Radius for SIMBAD query
bbox_size = query_radius_deg * 2  # Bounding box size (full width, twice the radius)
radii_arcmin = [15, 20, 25]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

# Query SIMBAD if no cache exists
if not os.path.exists(catalog_filename):
    print(f"Querying SIMBAD for all objects near Bullet Cluster with radius {query_radius_deg} deg...")
    result = custom_simbad.query_region(bullet_coord, radius=query_radius_deg * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print("SIMBAD query columns:", result.colnames)
    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Define bounding box for random points (4°x4° square)
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

# Filter AGN/QSO within bounding box
agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

# Convert to float to avoid warnings
agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

# Drop NaNs just in case
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

# Create SkyCoord with clean floats
ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [15, 20, 25]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'
query_radius_deg = 2.0  # larger radius for query

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

print(f"Querying SIMBAD for all objects near Bullet Cluster with radius {query_radius_deg} deg...")
result = custom_simbad.query_region(bullet_coord, radius=query_radius_deg * u.deg)
if result is None:
    raise ValueError("SIMBAD query returned no results.")

print(f"Total SIMBAD objects returned: {len(result)}")

# Show otype counts to understand object types returned
otype_counts = result['otype'].value_counts()
print("SIMBAD otype value counts (top 20):")
print(otype_counts.head(20))

df = result.to_pandas()

# Filter only AGN, QSO, BLLac types
otype_filter = df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)
df_filtered = df[otype_filter]

print(f"Number of AGN/QSO/BLLac objects after filtering: {len(df_filtered)}")

if df_filtered.empty:
    raise ValueError("No AGN/QSO/BLLac objects found in region.")

# Convert coordinates properly
coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
df_filtered.loc[:, 'ra'] = coords.ra.deg
df_filtered.loc[:, 'dec'] = coords.dec.deg

# Save filtered catalog
df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

# Filter AGN/QSO within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

# Drop NaNs just in case
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

# Create SkyCoord for filtered objects
ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [15, 20, 25]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

# Query SIMBAD if no cache exists
if not os.path.exists(catalog_filename):
    print(f"Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
    result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print(f"Total SIMBAD objects returned: {len(result)}")

    # Fix for otype value counts:
    otype_array = result['otype'].filled().astype(str)
    otype_series = pd.Series(otype_array)
    otype_counts = otype_series.value_counts()
    print("SIMBAD otype value counts (top 20):")
    print(otype_counts.head(20))

    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords =

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3,5,10,15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

# Query SIMBAD if no cache exists
if not os.path.exists(catalog_filename):
    print(f"Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
    result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print(f"Total SIMBAD objects returned: {len(result)}")

    # Fix for otype value counts:
    otype_array = result['otype'].filled().astype(str)
    otype_series = pd.Series(otype_array)
    otype_counts = otype_series.value_counts()
    print("SIMBAD otype value counts (top 20):")
    print(otype_counts.head(20))

    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter AGN/QSO within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_related.csv'

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

# Query SIMBAD if no cache exists
if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
    result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print(f"Total SIMBAD objects returned: {len(result)}")

    df = result.to_pandas()

    # Define BH-related types
    bh_types = ['AGN', 'QSO', 'BLLac', 'X', 'Rad', 'EmG']
    pattern = '|'.join(bh_types)

    # Filter objects matching BH-related types
    df_filtered = df[df['otype'].str.contains(pattern, case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No BH-related objects found in region.")

    # Fix RA/Dec columns
    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} BH-related sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter BH-related sources within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

bh_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if bh_subset.empty:
    raise ValueError("No BH-related sources found within bounding box. Check catalog or field depth.")

# Convert to floats & drop NaNs
bh_subset = bh_subset.copy()
bh_subset['ra'] = bh_subset['ra'].astype(float)
bh_subset['dec'] = bh_subset['dec'].astype(float)
bh_subset = bh_subset.dropna(subset=['ra', 'dec'])
print(f"Number of BH-related points after dropping NaNs: {len(bh_subset)}")

# Create SkyCoord from cleaned data
ra_vals = bh_subset['ra'].to_numpy(dtype=float)
dec_vals = bh_subset['dec'].to_numpy(dtype=float)
bh_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed BH-related sources near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(bh_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count BH-related sources near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(bh_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== BH-related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_conservative.csv'

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')

# Query SIMBAD if no cache exists
if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
    result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print(f"Total SIMBAD objects returned: {len(result)}")

    df = result.to_pandas()

    # Filter only conservative BH-related types
    bh_types = ['AGN', 'QSO', 'BLLac']
    df_filtered = df[df['otype'].str.fullmatch('|'.join(bh_types), case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No conservative BH-related objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} conservative BH-related sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Define bounding box limits
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No conservative BH-related objects found within bounding box.")

agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed BH-related objects near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count BH-related objects near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== Conservative BH-related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_redshift_filtered.csv'

# Cluster redshift and tolerance (adjust as needed)
cluster_z = 0.3
z_tol = 0.05

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype', 'z_value')  # Add redshift

print(f"Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)

if result is None:
    raise ValueError("SIMBAD query returned no results.")

print(f"Total SIMBAD objects returned: {len(result)}")

df = result.to_pandas()

# Convert redshift to numeric, coerce errors to NaN
df['z_value'] = pd.to_numeric(df['z_value'], errors='coerce')

# Define BH-related types to include conservatively
bh_types = ['AGN', 'QSO', 'BLLac']

# Filter for BH-related types (case insensitive full match)
df_filtered = df[df['otype'].str.fullmatch('|'.join(bh_types), case=False, na=False)]

# Filter objects with redshift within cluster_z ± z_tol
df_filtered = df_filtered[(df_filtered['z_value'] >= cluster_z - z_tol) & (df_filtered['z_value'] <= cluster_z + z_tol)]

if df_filtered.empty:
    raise ValueError("No BH-related objects found near cluster redshift within tolerance.")

print(f"Number of BH-related objects near cluster redshift: {len(df_filtered)}")

# Convert ra/dec to floats, drop NaNs
df_filtered = df_filtered.dropna(subset=['ra', 'dec'])
df_filtered['ra'] = df_filtered['ra'].astype(float)
df_filtered['dec'] = df_filtered['dec'].astype(float)

# Save filtered catalog
df_filtered[['main_id', 'ra', 'dec', 'otype', 'z_value']].to_csv(catalog_filename, index=False)
print(f"Saved filtered BH-related sources to {catalog_filename}")

# Filter BH objects inside bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

bh_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if bh_subset.empty:
    raise ValueError("No BH-related objects found within bounding box. Check data or parameters.")

ra_vals = bh_subset['ra'].to_numpy(dtype=float)
dec_vals = bh_subset['dec'].to_numpy(dtype=float)
bh_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed BH-related objects near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(bh_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count BH-related objects near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(bh_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== BH-related Object Clustering near Bullet Cluster (z filtered) ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bullet_z = 0.296
z_tol = 0.05
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_related.csv'

# Conservative BH-related SIMBAD types
bh_types = [
    'AGN', 'QSO', 'BLLac', 'X', 'Rad', 'EmG', 'Seyfert', 'Sy1', 'Sy2',
    'LINER', 'BH?', 'BLAZAR'
]

# Clear cache to force fresh query
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype', 'rvz_redshift')  # Request object types and redshift

print(f"Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
if result is None:
    raise ValueError("SIMBAD query returned no results.")

print(f"Total SIMBAD objects returned: {len(result)}")
df = result.to_pandas()

# Convert redshift column to numeric, coercing errors to NaN
df['rvz_redshift'] = pd.to_numeric(df['rvz_redshift'], errors='coerce')

# Filter rows by BH types (case-insensitive exact match)
pattern = '|'.join(bh_types)
df_filtered = df[df['otype'].str.fullmatch(pattern, case=False, na=False)]

# Filter by redshift within tolerance
df_filtered = df_filtered[
    (df_filtered['rvz_redshift'] >= bullet_z - z_tol) &
    (df_filtered['rvz_redshift'] <= bullet_z + z_tol)
]

if df_filtered.empty:
    raise ValueError("No BH-related objects found within redshift window.")

coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
df_filtered.loc[:, 'ra'] = coords.ra.deg
df_filtered.loc[:, 'dec'] = coords.dec.deg

df_filtered[['main_id', 'ra', 'dec', 'otype', 'rvz_redshift']].to_csv(catalog_filename, index=False)
print(f"Saved {len(df_filtered)} BH-related sources to {catalog_filename}")

# Define bounding box around Bullet Cluster
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No BH-related sources found within bounding box.")

agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

print("\n=== BH-related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import os
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord, match_coordinates_sky
import astropy.units as u
from astroquery.simbad import Simbad
from astroquery.ned import Ned
from astroquery.csc import CSC

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
search_radius_deg = 2.0  # degrees
match_radius_arcsec = 5.0  # cross-match radius tolerance

# Output filename
combined_catalog_filename = 'bullet_cluster_combined_bh_catalog.csv'

# Define search center coord
cluster_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# --- SIMBAD Query ---
def query_simbad():
    print("Querying SIMBAD...")
    custom_simbad = Simbad()
    custom_simbad.TIMEOUT = 180
    custom_simbad.add_votable_fields('otype', 'rvz_redshift')  # include redshift field

    result = custom_simbad.query_region(cluster_coord, radius=search_radius_deg * u.deg)
    if result is None:
        print("No SIMBAD results found.")
        return pd.DataFrame()

    df = result.to_pandas()

    # Select BH-related object types (can adjust as needed)
    bh_types = ['AGN', 'QSO', 'BLLac', 'Seyfert', 'Rad', 'X']
    mask = df['OTYPE'].str.contains('|'.join(bh_types), case=False, na=False)
    df_bh = df[mask].copy()

    # Rename and keep relevant columns
    df_bh = df_bh.rename(columns={'MAIN_ID': 'Name', 'RA': 'RA_deg', 'DEC': 'DEC_deg', 'RVZ_REDSHIFT': 'redshift', 'OTYPE': 'otype'})
    df_bh = df_bh[['Name', 'RA_deg', 'DEC_deg', 'otype', 'redshift']]
    print(f"SIMBAD BH-related sources: {len(df_bh)}")
    return df_bh

# --- NED Query ---
def query_ned():
    print("Querying NED...")
    try:
        ned_result = Ned.query_region(cluster_coord, radius=search_radius_deg * u.deg)
    except Exception as e:
        print(f"NED query failed: {e}")
        return pd.DataFrame()

    df = ned_result.to_pandas()

    # Filter BH-related types typical for NED (adjust if needed)
    bh_types = ['AGN', 'QSO', 'BL Lac', 'Seyfert', 'Radio source', 'X-ray source']
    mask = df['Type'].str.contains('|'.join(bh_types), case=False, na=False)
    df_bh = df[mask].copy()

    # Rename and keep relevant columns
    df_bh = df_bh.rename(columns={'Object Name': 'Name', 'RA': 'RA_deg', 'DEC': 'DEC_deg', 'Type': 'otype'})
    df_bh = df_bh[['Name', 'RA_deg', 'DEC_deg', 'otype']]
    print(f"NED BH-related sources: {len(df_bh)}")
    return df_bh

# --- CSC Query ---
def query_csc():
    print("Querying Chandra Source Catalog (CSC)...")
    try:
        csc_result = CSC.query_region(cluster_coord, radius=search_radius_deg * u.deg)
    except Exception as e:
        print(f"CSC query failed: {e}")
        return pd.DataFrame()

    df = csc_result.to_pandas()
    if df.empty:
        return df

    # CSC sources are mostly X-ray point sources; consider all as BH candidates
    df_bh = df.rename(columns={'Source_Name': 'Name', 'RA': 'RA_deg', 'DEC': 'DEC_deg'})
    df_bh = df_bh[['Name', 'RA_deg', 'DEC_deg']]
    df_bh['otype'] = 'CSC_Xray'
    print(f"CSC sources found: {len(df_bh)}")
    return df_bh

# --- Cross-match catalogs by position ---
def crossmatch_catalogs(dfs, max_sep_arcsec=5.0):
    """
    dfs: list of DataFrames with RA_deg, DEC_deg columns
    max_sep_arcsec: matching radius tolerance

    Returns combined DataFrame of unique sources
    """
    print("Cross-matching catalogs...")
    # Start with first catalog as base
    base_df = dfs[0].copy()
    base_coords = SkyCoord(base_df['RA_deg'], base_df['DEC_deg'], unit='deg')

    for i, df in enumerate(dfs[1:], start=2):
        coords = SkyCoord(df['RA_deg'], df['DEC_deg'], unit='deg')

        # Match df coords to base_df coords
        idx, sep2d, _ = match_coordinates_sky(coords, base_coords)

        sep_mask = sep2d.arcsec > max_sep_arcsec
        # Keep only sources from df that do NOT match base_df within max_sep_arcsec
        new_sources = df[sep_mask].copy()

        # Append new unique sources to base_df
        base_df = pd.concat([base_df, new_sources], ignore_index=True)

        # Update base_coords
        base_coords = SkyCoord(base_df['RA_deg'], base_df['DEC_deg'], unit='deg')

        print(f"After adding catalog {i}, total unique sources: {len(base_df)}")

    return base_df.reset_index(drop=True)

# --- Main processing ---
def main():
    # Remove cache if exists
    for fname in ['bullet_cluster_simbad.csv', 'bullet_cluster_ned.csv', 'bullet_cluster_csc.csv', combined_catalog_filename]:
        if os.path.exists(fname):
            os.remove(fname)
            print(f"Deleted old cache file {fname}")

    simbad_df = query_simbad()
    if not simbad_df.empty:
        simbad_df.to_csv('bullet_cluster_simbad.csv', index=False)

    ned_df = query_ned()
    if not ned_df.empty:
        ned_df.to_csv('bullet_cluster_ned.csv', index=False)

    csc_df = query_csc()
    if not csc_df.empty:
        csc_df.to_csv('bullet_cluster_csc.csv', index=False)

    # Collect dataframes to crossmatch, skip empty
    dfs = [df for df in [simbad_df, ned_df, csc_df] if not df.empty]
    if not dfs:
        print("No data retrieved from any catalog.")
        return

    combined_df = crossmatch_catalogs(dfs, max_sep_arcsec=match_radius_arcsec)
    print(f"Total unique BH-related sources after crossmatch: {len(combined_df)}")

    combined_df.to_csv(combined_catalog_filename, index=False)
    print(f"Saved combined catalog to {combined_catalog_filename}")

if __name__ == "__main__":
    main()

from astroquery.heasarc import Heasarc
import astropy.units as u
from astropy.coordinates import SkyCoord

heasarc = Heasarc()

# Search radius
radius = 2.0 * u.deg

# Bullet cluster center
coord = SkyCoord(ra=104.5, dec=-55.9, unit='deg')

# Query CSC (dataset 'csc2')
result = heasarc.query_region(coord, mission='csc2', radius=radius)

if result is None or len(result) == 0:
    print("No CSC sources found.")
else:
    print(f"Found {len(result)} CSC sources.")
    df = result.to_pandas()
    print(df.head())

from astroquery.heasarc import Heasarc
import astropy.units as u
from astropy.coordinates import SkyCoord

heasarc = Heasarc()

# Search radius
radius = 2.0 * u.deg

# Bullet cluster center
coord = SkyCoord(ra=104.5, dec=-55.9, unit='deg')

# Query CSC (dataset 'csc2')
result = heasarc.query_region(coord, mission='csc2', radius=radius)

if result is None or len(result) == 0:
    print("No CSC sources found.")
else:
    print(f"Found {len(result)} CSC sources.")
    df = result.to_pandas()
    print(df.head())

from astroquery.heasarc import Heasarc
import astropy.units as u
from astropy.coordinates import SkyCoord

heasarc = Heasarc()

radius = 2.0 * u.deg
coord = SkyCoord(ra=104.5, dec=-55.9, unit='deg')

try:
    result = heasarc.query_region(coord, catalog='csc2', radius=radius)
    if result is None or len(result) == 0:
        print("No CSC sources found.")
    else:
        print(f"Found {len(result)} CSC sources.")
        df = result.to_pandas()
        print(df.head())
except Exception as e:
    print("Error querying CSC:", e)

from astroquery.heasarc import Heasarc
from astropy.coordinates import SkyCoord

heasarc = Heasarc()

coord = SkyCoord(ra=104.5, dec=-55.9, unit='deg')
radius = '2 deg'  # Pass as string with unit, not astropy Quantity

try:
    result = heasarc.query_region(coord, catalog='csc2', radius=radius)
    if result is None or len(result) == 0:
        print("No CSC sources found.")
    else:
        print(f"Found {len(result)} CSC sources.")
        df = result.to_pandas()
        print(df.head())
except Exception as e:
    print("Error querying CSC:", e)

pip install astroquery-csc

pip install --upgrade astroquery

from astroquery.csc import Catalog

from astroquery.heasarc import Heasarc
from astropy.coordinates import SkyCoord
import astropy.units as u

heasarc = Heasarc()

# Define coordinates and radius
coord = SkyCoord(ra=104.5, dec=-55.9, unit=(u.deg, u.deg))
radius = 2 * u.deg

# ADQL query to get all CSC sources within radius
adql_query = f"""
SELECT * FROM csc2
WHERE CONTAINS(POINT('ICRS', ra, dec),
               CIRCLE('ICRS', {coord.ra.degree}, {coord.dec.degree}, {radius.to(u.deg).value})) = 1
"""

result = heasarc.query_criteria(class_='csc2', adql=adql_query)

print(result)

from astroquery.heasarc import Heasarc
from astropy.coordinates import SkyCoord
import astropy.units as u

heasarc = Heasarc()

# Define coordinates and radius
coord = SkyCoord(ra=104.5, dec=-55.9, unit=(u.deg, u.deg))
radius = 2 * u.deg

try:
    result = heasarc.query_region(coord, mission='csc2', radius=radius)
    print(result)
except Exception as e:
    print("Error querying CSC:", e)

from astroquery.heasarc import Heasarc
from astropy.coordinates import SkyCoord
import astropy.units as u

heasarc = Heasarc()

coord = SkyCoord(ra=104.5, dec=-55.9, unit=(u.deg, u.deg))
radius = 2 * u.deg

try:
    # Use 'catalog' instead of 'mission'
    result = heasarc.query_region(coord, catalog='csc2', radius=radius)
    print(result)
except Exception as e:
    print("Error querying CSC:", e)

from astroquery.heasarc import Heasarc
from astropy.coordinates import SkyCoord
import astropy.units as u

heasarc = Heasarc()
coord = SkyCoord(ra=104.5, dec=-55.9, unit=(u.deg, u.deg))
radius = 2 * u.deg

try:
    result = heasarc.query_region(coord, catalog='rosat', radius=radius)
    print(f"Number of sources in ROSAT: {len(result)}")
except Exception as e:
    print("Error querying ROSAT catalog:", e)

from astroquery.vizier import Vizier
from astropy.coordinates import SkyCoord
import astropy.units as u
import pandas as pd

# Configure Vizier: no row limit, fetch all results
Vizier.ROW_LIMIT = -1

# Define target coordinates and search radius
bullet_coord = SkyCoord(ra=104.5, dec=-55.9, unit=(u.deg, u.deg))
search_radius = 2 * u.deg  # 2 degree radius around Bullet Cluster

# Define catalogs of interest (VizieR IDs)
# Some popular X-ray and AGN catalogs:
catalogs = {
    "ROSAT Bright Source": "IX/10A",
    "ROSAT Faint Source": "IX/10B",
    "Chandra Source Catalog": "J/ApJS/224/15",
    "Veron AGN/QSO": "VII/258",
    "4XMM-DR10 (XMM-Newton)": "IX/103/xmm4",
    # Add more as needed
}

results = {}

for name, cat_id in catalogs.items():
    print(f"\nQuerying {name} ({cat_id})...")
    try:
        # Query region around Bullet Cluster
        query_result = Vizier.query_region(bullet_coord, radius=search_radius, catalog=cat_id)
        if query_result:
            df = query_result[0].to_pandas()
            print(f"Found {len(df)} sources in {name}")
            results[name] = df
        else:
            print(f"No sources found in {name}")
            results[name] = pd.DataFrame()
    except Exception as e:
        print(f"Error querying {name}: {e}")
        results[name] = pd.DataFrame()

# Example: Save ROSAT Bright Source catalog results to CSV
if not results["ROSAT Bright Source"].empty:
    results["ROSAT Bright Source"].to_csv("rosat_bright_sources_bullet.csv", index=False)
    print("\nSaved ROSAT Bright Source catalog results to rosat_bright_sources_bullet.csv")

# You can inspect or process `results` dict now for each catalog

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.vizier import Vizier
from scipy.stats import poisson, ks_2samp

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Vizier setup - limit columns to speed up queries
Vizier.ROW_LIMIT = -1  # no row limit

def query_vizier(catalog_id):
    print(f"Querying {catalog_id} catalog...")
    result = Vizier.query_region(bullet_coord, radius=2.0 * u.deg, catalog=catalog_id)
    if not result:
        print(f"No sources found in {catalog_id}")
        return None
    df = result[0].to_pandas()
    print(f"Found {len(df)} sources in {catalog_id}")
    return df

# Query Veron AGN/QSO catalog VII/258
veron_df = query_vizier("VII/258")

# Query ROSAT Bright and Faint Source catalogs IX/10A and IX/10B
rosat_bright_df = query_vizier("IX/10A")
rosat_faint_df = query_vizier("IX/10B")

# Combine ROSAT sources (bright + faint)
rosat_df = pd.concat([rosat_bright_df, rosat_faint_df], ignore_index=True) if rosat_bright_df is not None and rosat_faint_df is not None else None

def prepare_coords(df, ra_col, dec_col):
    return SkyCoord(ra=df[ra_col].values * u.deg, dec=df[dec_col].values * u.deg)

def analyze_catalog(df, coord_col_ra, coord_col_dec, catalog_name):
    if df is None or df.empty:
        print(f"No data for {catalog_name}")
        return

    coords = prepare_coords(df, coord_col_ra, coord_col_dec)

    # Filter sources in bounding box
    ra_min = bullet_ra - bbox_size / 2
    ra_max = bullet_ra + bbox_size / 2
    dec_min = bullet_dec - bbox_size / 2
    dec_max = bullet_dec + bbox_size / 2

    in_box_mask = (df[coord_col_ra] >= ra_min) & (df[coord_col_ra] <= ra_max) & \
                  (df[coord_col_dec] >= dec_min) & (df[coord_col_dec] <= dec_max)
    df_box = df[in_box_mask].copy()
    coords_box = prepare_coords(df_box, coord_col_ra, coord_col_dec)

    print(f"{catalog_name}: {len(df_box)} sources in bounding box")

    observed_counts = {}
    cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

    for radius in radii_arcmin:
        sep = cluster_center.separation(coords_box)
        count = np.sum(sep < radius * u.arcmin)
        observed_counts[radius] = count

    # Random controls
    random_counts = {r: [] for r in radii_arcmin}
    for _ in range(n_random_trials):
        rand_ra = np.random.uniform(ra_min, ra_max)
        rand_dec = np.random.uniform(dec_min, dec_max)
        rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

        for radius in radii_arcmin:
            sep = rand_point.separation(coords_box)
            count = np.sum(sep < radius * u.arcmin)
            random_counts[radius].append(count)

    # Print results
    print(f"\n=== {catalog_name} Clustering near Bullet Cluster ===")
    print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
    print("-" * 80)
    for radius in radii_arcmin:
        obs = observed_counts[radius]
        rand_list = np.array(random_counts[radius])
        mean_rand = rand_list.mean()
        p_poisson = poisson.sf(obs - 1, mean_rand)
        p_ks = ks_2samp([obs], rand_list).pvalue
        print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

# Run analysis on Veron catalog
analyze_catalog(veron_df, 'RAJ2000', 'DEJ2000', 'Veron AGN/QSO')

# Run analysis on ROSAT catalog
if rosat_df is not None:
    # ROSAT columns are typically 'RAJ2000', 'DEJ2000'
    analyze_catalog(rosat_df, 'RAJ2000', 'DEJ2000', 'ROSAT (Bright+Faint)')
else:
    print("No ROSAT data available")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.vizier import Vizier

# Bullet cluster parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000

def analyze_catalog(df, coord_col_ra, coord_col_dec, catalog_name):
    if df is None or df.empty:
        print(f"No data for {catalog_name}")
        return

    # Convert RA/Dec columns to numeric floats, coerce errors to NaN
    df[coord_col_ra] = pd.to_numeric(df[coord_col_ra], errors='coerce')
    df[coord_col_dec] = pd.to_numeric(df[coord_col_dec], errors='coerce')

    # Drop rows with invalid coords
    df = df.dropna(subset=[coord_col_ra, coord_col_dec])

    # Create SkyCoord array
    coords = SkyCoord(ra=df[coord_col_ra].values * u.deg, dec=df[coord_col_dec].values * u.deg)

    # Filter sources inside bounding box
    ra_min = bullet_ra - bbox_size / 2
    ra_max = bullet_ra + bbox_size / 2
    dec_min = bullet_dec - bbox_size / 2
    dec_max = bullet_dec + bbox_size / 2

    in_box_mask = (df[coord_col_ra] >= ra_min) & (df[coord_col_ra] <= ra_max) & \
                  (df[coord_col_dec] >= dec_min) & (df[coord_col_dec] <= dec_max)
    df_box = df[in_box_mask].copy()
    coords_box = SkyCoord(ra=df_box[coord_col_ra].values * u.deg, dec=df_box[coord_col_dec].values * u.deg)

    print(f"{catalog_name}: {len(df_box)} sources in bounding box")

    cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

    observed_counts = {}
    for radius in radii_arcmin:
        sep = cluster_center.separation(coords_box)
        count = np.sum(sep < radius * u.arcmin)
        observed_counts[radius] = count

    # Random points controls
    random_counts = {r: [] for r in radii_arcmin}
    for _ in range(n_random_trials):
        rand_ra = np.random.uniform(ra_min, ra_max)
        rand_dec = np.random.uniform(dec_min, dec_max)
        rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

        for radius in radii_arcmin:
            sep = rand_point.separation(coords_box)
            count = np.sum(sep < radius * u.arcmin)
            random_counts[radius].append(count)

    # Print stats
    print(f"\n=== {catalog_name} Clustering near Bullet Cluster ===")
    print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
    print("-" * 80)
    for radius in radii_arcmin:
        obs = observed_counts[radius]
        rand_list = np.array(random_counts[radius])
        mean_rand = rand_list.mean()
        p_poisson = poisson.sf(obs - 1, mean_rand)
        p_ks = ks_2samp([obs], rand_list).pvalue
        print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

# Vizier settings: no row limit for full catalog pulls
Vizier.ROW_LIMIT = -1

# Query catalogs you want to compare with SIMBAD
# Example: Veron AGN/QSO catalog (VII/258)
print("Querying Veron AGN/QSO catalog (VII/258)...")
veron_catalog = Vizier.get_catalogs('VII/258')
veron_df = veron_catalog[0].to_pandas()

# Example: ROSAT Bright Source catalog (IX/10A)
print("Querying ROSAT Bright Source catalog (IX/10A)...")
rosat_bright = Vizier.get_catalogs('IX/10A')
rosat_bright_df = rosat_bright[0].to_pandas()

# Example: ROSAT Faint Source catalog (IX/10B)
print("Querying ROSAT Faint Source catalog (IX/10B)...")
rosat_faint = Vizier.get_catalogs('IX/10B')
rosat_faint_df = rosat_faint[0].to_pandas()

# Run analyses separately
analyze_catalog(veron_df, 'RAJ2000', 'DEJ2000', 'Veron AGN/QSO')
analyze_catalog(rosat_bright_df, 'RAJ2000', 'DEJ2000', 'ROSAT Bright Source')
analyze_catalog(rosat_faint_df, 'RAJ2000', 'DEJ2000', 'ROSAT Faint Source')

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.vizier import Vizier
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_4XMM_DR10.csv'

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Vizier settings
Vizier.ROW_LIMIT = -1  # no row limit
catalog_id = 'IX/103/xmm4'  # 4XMM-DR10 catalog ID in Vizier

# Clear cache if exists
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename} to force fresh query.")

print(f"Querying 4XMM-DR10 catalog ({catalog_id}) near Bullet Cluster with radius 2.0 deg...")
result = Vizier.query_region(bullet_coord, radius=2.0 * u.deg, catalog=catalog_id)

if not result or len(result) == 0:
    raise ValueError("No sources found in 4XMM-DR10 for the specified region.")

df = result[0].to_pandas()
print(f"Total 4XMM-DR10 sources found: {len(df)}")

# Filter to bounding box 1 deg square around center (to match previous analyses)
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

df_bbox = df[(df['RAJ2000'] >= ra_min) & (df['RAJ2000'] <= ra_max) &
             (df['DEJ2000'] >= dec_min) & (df['DEJ2000'] <= dec_max)].copy()

print(f"Sources in bounding box: {len(df_bbox)}")

# Drop rows with NaN RA or Dec
df_bbox = df_bbox.dropna(subset=['RAJ2000', 'DEJ2000'])

# Create SkyCoord objects for sources
source_coords = SkyCoord(ra=df_bbox['RAJ2000'].values * u.deg, dec=df_bbox['DEJ2000'].values * u.deg)
cluster_center = bullet_coord

# Calculate observed counts within each radius
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(source_coords)
    observed_counts[radius] = np.sum(sep < radius * u.arcmin)

# Random counts
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)
    for radius in radii_arcmin:
        sep = rand_point.separation(source_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print results
print("\n=== 4XMM-DR10 Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_arr = np.array(random_counts[radius])
    mean_rand = rand_arr.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_arr).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.vizier import Vizier
import os

bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees square
search_radius = 1.0  # degrees, smaller than before
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_4XMM_DR10.csv'

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)
Vizier.ROW_LIMIT = -1  # no row limit
catalog_id = 'IX/103/xmm4'  # 4XMM-DR10 catalog

# Clear cache
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file {catalog_filename}")

print(f"Querying 4XMM-DR10 catalog near Bullet Cluster with radius {search_radius} deg...")
result = Vizier.query_region(bullet_coord, radius=search_radius * u.deg, catalog=catalog_id)

if not result or len(result) == 0:
    raise ValueError("No sources found in 4XMM-DR10 for the specified region.")

df = result[0].to_pandas()
print(f"Total 4XMM-DR10 sources found: {len(df)}")

# Filter by bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

df_bbox = df[(df['RAJ2000'] >= ra_min) & (df['RAJ2000'] <= ra_max) &
             (df['DEJ2000'] >= dec_min) & (df['DEJ2000'] <= dec_max)].copy()

print(f"Sources in bounding box: {len(df_bbox)}")

df_bbox = df_bbox.dropna(subset=['RAJ2000', 'DEJ2000'])

source_coords = SkyCoord(ra=df_bbox['RAJ2000'].values * u.deg, dec=df_bbox['DEJ2000'].values * u.deg)
cluster_center = bullet_coord

observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(source_coords)
    observed_counts[radius] = np.sum(sep < radius * u.arcmin)

random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)
    for radius in radii_arcmin:
        sep = rand_point.separation(source_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

print("\n=== 4XMM-DR10 Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_arr = np.array(random_counts[radius])
    mean_rand = rand_arr.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_arr).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# === Parameters ===
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees around cluster center
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_related.csv'
query_radius_deg = 2.0

# === Delete cache to force fresh query ===
if os.path.exists(catalog_filename):
    os.remove(catalog_filename)
    print(f"Deleted old cache file: {catalog_filename}")

# === Define cluster center ===
cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# === Custom SIMBAD query ===
custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype', 'rvz_redshift')  # Use proper redshift field

print(f"Querying SIMBAD for all objects near Bullet Cluster with radius {query_radius_deg} deg...")
result = custom_simbad.query_region(cluster_center, radius=query_radius_deg * u.deg)

if result is None or len(result) == 0:
    raise ValueError("SIMBAD query returned no results.")

print(f"Total SIMBAD objects returned: {len(result)}")

# === Convert to DataFrame and filter ===
df = result.to_pandas()
df.columns = df.columns.str.strip()  # Clean column names

# Conservative BH-related object types
bh_related_keywords = ['AGN', 'QSO', 'BLLac', 'Seyfert', 'LINER', 'EmG', 'X']  # optional: add 'ClG'

pattern = '|'.join(bh_related_keywords)
df_bh = df[df['otype'].str.contains(pattern, case=False, na=False)].copy()

# Drop rows with NaN coords
df_bh = df_bh.dropna(subset=['ra', 'dec'])
print(f"Saved {len(df_bh)} BH-related sources to {catalog_filename}")

# Convert coordinates to float
df_bh['ra'] = df_bh['ra'].astype(float)
df_bh['dec'] = df_bh['dec'].astype(float)
print(f"Number of BH-related points after dropping NaNs: {len(df_bh)}")

# Save catalog
df_bh[['main_id', 'ra', 'dec', 'otype', 'rvz_redshift']].to_csv(catalog_filename, index=False)

# === Bounding box limits ===
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

# Filter within 1x1 deg box
in_box = df_bh[
    (df_bh['ra'] >= ra_min) & (df_bh['ra'] <= ra_max) &
    (df_bh['dec'] >= dec_min) & (df_bh['dec'] <= dec_max)
]

if in_box.empty:
    raise ValueError("No BH-related objects found in bounding box.")

agn_coords = SkyCoord(ra=in_box['ra'].values * u.deg, dec=in_box['dec'].values * u.deg)

# === Observed count around cluster ===
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    observed_counts[radius] = np.sum(sep < radius * u.arcmin)

# === Control: Random sky points in bounding box ===
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for r in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        random_counts[r].append(np.sum(sep < r * u.arcmin))

# === Print results ===
print("\n=== BH-related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for r in radii_arcmin:
    obs = observed_counts[r]
    rand_array = np.array(random_counts[r])
    mean_rand = rand_array.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_array).pvalue
    print(f"{r:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os

# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_agn_qso.csv'

bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype')  # Request object types in query

if not os.path.exists(catalog_filename):
    print("Querying SIMBAD for all objects near Bullet Cluster...")
    result = custom_simbad.query_region(bullet_coord, radius=0.5 * u.deg)
    if result is None:
        raise ValueError("SIMBAD query returned no results.")

    print("SIMBAD query columns:", result.colnames)
    df = result.to_pandas()
    print("DataFrame columns:", df.columns.tolist())

    # Filter only AGN, QSO, BLLac types
    df_filtered = df[df['otype'].str.contains('AGN|QSO|BLLac', case=False, na=False)]

    if df_filtered.empty:
        raise ValueError("No AGN/QSO/BLLac objects found in region.")

    coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
    df_filtered.loc[:, 'ra'] = coords.ra.deg
    df_filtered.loc[:, 'dec'] = coords.dec.deg

    df_filtered[['main_id', 'ra', 'dec', 'otype']].to_csv(catalog_filename, index=False)
    print(f"Saved {len(df_filtered)} AGN/QSO/BLLac sources to {catalog_filename}")

else:
    print(f"Using cached file: {catalog_filename}")
    df_filtered = pd.read_csv(catalog_filename)

# Filter AGN/QSO within bounding box
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2

agn_subset = df_filtered[
    (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
    (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]

if agn_subset.empty:
    raise ValueError("No AGN/QSO found within bounding box. Check catalog or field depth.")

# Copy to avoid SettingWithCopyWarning and convert to floats
agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)

# DEBUG: check types and NaNs
print("RA dtype:", agn_subset['ra'].dtype)
print("DEC dtype:", agn_subset['dec'].dtype)
print("Any NaNs in RA?", agn_subset['ra'].isna().any())
print("Any NaNs in DEC?", agn_subset['dec'].isna().any())

# Drop rows with NaNs just in case
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")

# Create SkyCoord with clean float arrays
ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)

cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)

# Count observed AGN/QSO near cluster center
observed_counts = {}
for radius in radii_arcmin:
    sep = cluster_center.separation(agn_coords)
    count = np.sum(sep < radius * u.arcmin)
    observed_counts[radius] = count

# Count AGN/QSO near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
    rand_ra = np.random.uniform(ra_min, ra_max)
    rand_dec = np.random.uniform(dec_min, dec_max)
    rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)

    for radius in radii_arcmin:
        sep = rand_point.separation(agn_coords)
        count = np.sum(sep < radius * u.arcmin)
        random_counts[radius].append(count)

# Print statistical summary
print("\n=== AGN/QSO Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
    obs = observed_counts[radius]
    rand_list = np.array(random_counts[radius])
    mean_rand = rand_list.mean()
    p_poisson = poisson.sf(obs - 1, mean_rand)
    p_ks = ks_2samp([obs], rand_list).pvalue
    print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

With redshift result
Deleted old cache file bullet_cluster_bh_related.csv to force fresh SIMBAD query.
Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...
Total SIMBAD objects returned: 7246
Saved 14 BH-related sources to bullet_cluster_bh_related.csv
Number of points after dropping NaNs: 14

=== BH-related Object Clustering near Bullet Cluster ===
Radius (arcmin)    | Observed | Mean Random  | Poisson p-val  | KS p-val
--------------------------------------------------------------------------------
3                  | 3        | 0.20         | 1.08e-03       | 0.032
5                  | 3        | 0.49         | 1.40e-02       | 0.144
10                 | 11       | 2.03         | 9.35e-06       | 0.040
15                 | 13       | 4.51         | 8.23e-04       | 0.134

Code
import numpy as np
import pandas as pd
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.stats import poisson, ks_2samp
from astroquery.simbad import Simbad
import os


# Parameters
bullet_ra = 104.5
bullet_dec = -55.9
bullet_z = 0.296
z_tol = 0.05
bbox_size = 1.0  # degrees (1x1 deg box)
radii_arcmin = [3, 5, 10, 15]
n_random_trials = 1000
catalog_filename = 'bullet_cluster_bh_related.csv'


# Conservative BH-related SIMBAD types
bh_types = [
   'AGN', 'QSO', 'BLLac', 'X', 'Rad', 'EmG', 'Seyfert', 'Sy1', 'Sy2',
   'LINER', 'BH?', 'BLAZAR'
]


# Clear cache to force fresh query
if os.path.exists(catalog_filename):
   os.remove(catalog_filename)
   print(f"Deleted old cache file {catalog_filename} to force fresh SIMBAD query.")


bullet_coord = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)


custom_simbad = Simbad()
custom_simbad.TIMEOUT = 120
custom_simbad.add_votable_fields('otype', 'rvz_redshift')  # Request object types and redshift


print(f"Querying SIMBAD for all objects near Bullet Cluster with radius 2.0 deg...")
result = custom_simbad.query_region(bullet_coord, radius=2.0 * u.deg)
if result is None:
   raise ValueError("SIMBAD query returned no results.")


print(f"Total SIMBAD objects returned: {len(result)}")
df = result.to_pandas()


# Convert redshift column to numeric, coercing errors to NaN
df['rvz_redshift'] = pd.to_numeric(df['rvz_redshift'], errors='coerce')


# Filter rows by BH types (case-insensitive exact match)
pattern = '|'.join(bh_types)
df_filtered = df[df['otype'].str.fullmatch(pattern, case=False, na=False)]


# Filter by redshift within tolerance
df_filtered = df_filtered[
   (df_filtered['rvz_redshift'] >= bullet_z - z_tol) &
   (df_filtered['rvz_redshift'] <= bullet_z + z_tol)
]


if df_filtered.empty:
   raise ValueError("No BH-related objects found within redshift window.")


coords = SkyCoord(df_filtered['ra'], df_filtered['dec'], unit=(u.deg, u.deg))
df_filtered.loc[:, 'ra'] = coords.ra.deg
df_filtered.loc[:, 'dec'] = coords.dec.deg


df_filtered[['main_id', 'ra', 'dec', 'otype', 'rvz_redshift']].to_csv(catalog_filename, index=False)
print(f"Saved {len(df_filtered)} BH-related sources to {catalog_filename}")


# Define bounding box around Bullet Cluster
ra_min = bullet_ra - bbox_size / 2
ra_max = bullet_ra + bbox_size / 2
dec_min = bullet_dec - bbox_size / 2
dec_max = bullet_dec + bbox_size / 2


agn_subset = df_filtered[
   (df_filtered['ra'] >= ra_min) & (df_filtered['ra'] <= ra_max) &
   (df_filtered['dec'] >= dec_min) & (df_filtered['dec'] <= dec_max)
]


if agn_subset.empty:
   raise ValueError("No BH-related sources found within bounding box.")


agn_subset = agn_subset.copy()
agn_subset['ra'] = agn_subset['ra'].astype(float)
agn_subset['dec'] = agn_subset['dec'].astype(float)
agn_subset = agn_subset.dropna(subset=['ra', 'dec'])
print(f"Number of points after dropping NaNs: {len(agn_subset)}")


ra_vals = agn_subset['ra'].to_numpy(dtype=float)
dec_vals = agn_subset['dec'].to_numpy(dtype=float)
agn_coords = SkyCoord(ra=ra_vals * u.deg, dec=dec_vals * u.deg)


cluster_center = SkyCoord(ra=bullet_ra * u.deg, dec=bullet_dec * u.deg)


# Count observed near cluster center
observed_counts = {}
for radius in radii_arcmin:
   sep = cluster_center.separation(agn_coords)
   count = np.sum(sep < radius * u.arcmin)
   observed_counts[radius] = count


# Count near random points in bounding box (control)
random_counts = {r: [] for r in radii_arcmin}
for _ in range(n_random_trials):
   rand_ra = np.random.uniform(ra_min, ra_max)
   rand_dec = np.random.uniform(dec_min, dec_max)
   rand_point = SkyCoord(ra=rand_ra * u.deg, dec=rand_dec * u.deg)


   for radius in radii_arcmin:
       sep = rand_point.separation(agn_coords)
       count = np.sum(sep < radius * u.arcmin)
       random_counts[radius].append(count)


print("\n=== BH-related Object Clustering near Bullet Cluster ===")
print(f"{'Radius (arcmin)':<18} | {'Observed':<8} | {'Mean Random':<12} | {'Poisson p-val':<14} | {'KS p-val'}")
print("-" * 80)
for radius in radii_arcmin:
   obs = observed_counts[radius]
   rand_list = np.array(random_counts[radius])
   mean_rand = rand_list.mean()
   p_poisson = poisson.sf(obs - 1, mean_rand)
   p_ks = ks_2samp([obs], rand_list).pvalue
   print(f"{radius:<18} | {obs:<8} | {mean_rand:<12.2f} | {p_poisson:<14.2e} | {p_ks:.3f}")

